Server Module 에 대한 코멘트

첫번째로 생각했던 모델의 경우에는 각각의 Thread가 동일한 serv_sock을 공유하고
서로 다른 epoll객체를 생성해서 관리하는 모델로 생각하였다. 그러나 이런 모델로
구현시에는 입력이 몰리게 되었을때, 하나의 epoll에 많은 연결이 될 수도 있어서
다른 모델을 생각하게 되었다.

============================================================================

두번째로 생각한 모델은 serv_sock을 관리하는 Main Thread를 따로 만들고 epoll
하나로 관리하는 모델이다. 이 경우에는 Sub Thread를 여러개 만들어 이 스레드에서
read, write를 하는 모델이다. 이렇게 epoll를 Sub Thread에서 공유함으로써 
이전 모델에는 존재하는 하나의 epoll에 많은 연결이 몰리는 문제는 해결할 수 
있을 것으로 예상된다. 그리고 epoll은 thread-safe하므로 문제 없이 구현가능
할것 같다.
 또한 Matching Module과의 관계에 있어서도 Request Pipe, Response Pipe 한 쌍으로
연결이 가능하기 때문에 서로 독립성을 유지하고 효율적이다. 파이프를 이용한 
연결의 경우에는 AIO를 이용하여 concurrency문제를 해결할 수 있을 것으로 보인다.

하지만 문제점도 존재한다. 두가지 모듈간에 communication을 할때, pipe를 통해서
하기 때문에 데이터의 복사가 낭비되어진다. 하지만 사용자가 임의로 matching
module을 만들어서 매칭 방식을 변경하고자 할 경우가 있을 것임으로 두 모듈간에
독립성을 중요시하여 이와 같이 구현하였다.

+추가
위의 데이터 복사에 대한 문제는 socket프로그래밍으로 해결가능하다. 파일
디스크립터를 matching module에게 전송해주고 이를 자체적인 queue로 구현해두어
사용자 입장에서는 Pipe를 통해서 오는 입력처럼 보이게 하려고 한다.

============================================================================

세번째 모델(2017.01.18)
serv_sock을 관리하고 connection을 받아주는 accept_thread를 만든다.
이 쓰레드는 serv_sock을 통해서 accept후에 이 fd를 matching module에게
보낸다. matching module은 이를 사용자가 이해하기 쉬운 개념인 pipe의 형태로
가공하여 사용자에게 전달하고 사용자는 이를 통해서 알고리즘을 구현한다.
또한 사용자가 구현한 알고리즘의 결과는 response_pipe를 통해서 server module로
전달되어진다. 이 결과에 대해서는 sub_thread가 전송할 책임을 지닌다.

세번째 모델의 경우에는 결국 모듈 개념으로 나누어지기는 했지만 단순한
웹 서버의 형태를 띠고 있었다. 또한 accept_thread에서 Matching Module에 있는
알고리즘으로 넘기기 위해서 필요한 fd전송의 오버헤드도 존재하고 또한 
Matching Algorithm의 속도에 너무 의존하는 형태가 되어버린다. 그리고 
Matching Module에서 Server Module로의 연결도 파이프로 되어있어서
불필요한 데이터 복사가 이루어진다. 

============================================================================

네번째 모델(2017.01.19)	/ C++
멀티프로세서를 이용하는 웹 서버의 형태를 띄고 있다.  메인 쓰레드는 accept를 할
책임과 역활을 지니고 있고, 이를 Queue에 넣는다. 여기서의 Queue는 Command라는
Interface의 형태를 띄는 값으로 채워지게 된다. 그리고 이러한 Command를 Thread
Pool에서 Command의 Execute()연산을 통해서 처리하게 된다. 

사용자의 알고리즘을 넣을수 있도록 하기 위해서는 결국 OOP의 개념이 들어가야 했다.
따라서 C++로 구현하게 되었고, 여기서는 Command 패턴을 이용하여 구현하였다.
이러한 구조로 하여 입력이 왔을 떄 뿐만이 아니라 사용자가 임의로 Queue에 
정의한 Command를 넣을 수 있도록 구현하였다.

-----------------------------------------------------------------------------

Queue의 처리 방법
Queue에 접근하는 Thread가 여럿 존재하므로 Concurrent문제를 해결하기 위하여 
Semaphore를 이용하였다. 내부적으로는 Linked List형태로 구현되었다. 중요한
점은 Pop이 호출된 이후에 Queue가 비어있게되면 서버는 busy wait상태가 되어버린다.
이를 막기 위해서 pop_sem_lock과 unlock에는 3의 비용을 넣고 push_sem_lock과
unlock에는 2의 비용을 넣었다. 그리고 나서 Queue가 비어있을 때의 pop을 하게되면
push_sem_unlock을 하여 pop은 불가능하고 push는 가능하게 하였다. 또한 이후에
첫번째 push에서 push이후에 pop_sem_unlock을 통해서 정상적으로 되돌리도록 하였다.
이를 통해서 system call을 최소화 하면서도 pop이후에 push가 실행될수 있도록
구현하였다.
또한 이를 통해서 Thread-pool에서의 쓰레드 관리도 semaphore를 통해서 자동으로
되어지기 때문에 불필요한 system-call를 막을 수 있다.

-----------------------------------------------------------------------------

Thread-pool에서의 자료구조
매칭 알고리즘의 처리는 thread-pool에서 이루어지지만 여기에 존재하는 데이터들을
적절히 모으고 concurrent문제도 처리해주는 자료구조가 필요하다. 이를 구현하는
방법에는 여러가지가 존재한다.

1. 해당 자료구조에 접근을 mutex로 관리하여 준다.
	장점 : 구현과 구조가 간단
	단점 : 자료구조에 접근이 많아지면 그만큼 mutex에 의해 block되어지기 
		때문에 상당히 비효율적이다.

2. thread마다 자료구조에 접근하기 위한 Queue를 만들고 단일 쓰레드에서 그 Queue들을
관리한다. 데이터를 push하는 연산은 큐에 넣어주고, pop해야 하는연산은 blocking상태로
대기한다. 
	장점 : push연산은 asynchronous하게 빨리 이루어진다.
               system-call이 이루어지지 않아서 빠르다.
	단점 : push연산의 순서가 바뀔 수 있다.
	       pop연산은 blocking하게 처리되어져야 한다.
	       busy wait를 해야 한다.

3. 두번째 방법을 보안하여 pop연산을 없애고 자료구조를 포함한 알고리즘을 queue에 넣는
방식이다. 그리고 데이터전송이 필요하게 되면 이를 CommandQueue에 넣어서 처리한다.
	장점 : 방식2의 장점
	       blocking이 전혀 이루어지지 않는다.
	단점 : push연산의 순서가 바뀔 수 있다.
	       busy wait를 해야 한다.

4. CommandQueue에서 썼던 방식의 queue를 이용한다. 이를 통해서 DataStructure에 push하고
또한 전송까지 책임진다. 데이터 전송은 AIO방식으로 한다.
	장점 : mutex를 통해서 관리하는 것보다 pop연산을 없앰으로써
	       DataStructure에 연산을 줄일수 있다.
	단점 : DataStructure에서의 연산이 크면 bottle-neck이 될수도 있다.

자료구조 결론 => 2,3번 방식의 경우 busy wait를 해야만 하기 때문에 차라리 1, 4번 방식이
더 좋아 보인다. DataStructure에 연산을 넣느냐 안넣느냐로 나뉘는데 DataStructure에서의
연산이 길고 오래걸린다면 1번을 아니면 4번으로 구현하는 것이 좋아보인다. 

-----------------------------------------------------------------------------





